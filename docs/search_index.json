[["index.html", "XAI Stories 2.0 Preface", " XAI Stories 2.0 2021-06-19 Preface This book is the result of a student projects for Interpretable Machine Learning course at the University of Warsaw and the University of Łódź. Each team has prepared one case study for selected XAI technique. The book chapters are written in the Markdown language. The simulations, data examples and visualizations were created with R (R Core Team 2018) and Python. The book was compiled with the bookdown package. We collaborated using github repository. Cover by kozaka93. Creative Commons License This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. References "],["foreword.html", "Foreword 0.1 Why? 0.2 What? 0.3 How? 0.4 About academic partners 0.5 About business partner", " Foreword Author: Przemyslaw Biecek (University of Warsaw 0.1 Why? In 2020, as part of the Interpretable Machine Learning course, students created XAI Stories, an ebook that collects the experiences of the subjects covered in the form of a series of chapters on different applications of XAI techniques. This was a great idea. Each team developed an interesting solution and then described it in a clear and interesting way. Some of these results were later presented at relevant industry conferences. This year we are continuing this experiment but focusing on applications in one sector - retail analytics. In cooperation with students from the universities of Warsaw and Lodz, as well as partners from McKinsey and Shumee, this ebook has been created - presenting various ideas and applications on how to use predictive modelling in retail, but also how to enrich these solutions with XAI. I hope that the presented solutions will trigger development of new interesting solutions implementing explainable machine learning in the retail industry 0.2 What? This ebook collects examples of the use of different methods from the XAI family for real-world predictive problems in retail. In the following chapters, we show example applications of different XAI techniques to problems in retail analytics. These examples are called XAI stories and like every good story, each one has a structure. It starts with a description of the predictive problem, goes on to describe the proposed model or models. The models are x-rays using XAI techniques to finish the chapter with a point. 0.3 How? For XAI stories to be credible they need not only a strong predictive model but also business validation of the proposed modeling and an explanation approach. Each group of students was assigned mentors from data scientists and experts within McKinsey Digital: a consultant and a data scientist. The mentors, together with the students, searched for the strengths and weaknesses of XAI applications in specific problems. At McKinsey Digital, we help our clients create change that matters—transformation, enabled by technology and sustained through capabilities. We drive transformation and build businesses by bringing together the capabilities needed to help organizations grow and thrive in the digital age. We help our clients harness the power of data and artificial intelligence, modernize core technology and capitalize on new technology, optimize and automate operations, fuel digital growth, create stunning digital experiences, and build digital talent and culture. 0.4 About academic partners The Faculty of Mathematics, Informatics, and Mechanics, University of Warsaw The Faculty of Mathematics, Informatics, and Mechanics Department offers a master’s degree with a specialization in mathematical statistics or a specialization in machine learning. The curriculum includes many interesting subjects related to computational statistics or deep learning. This book was prepared as part of the Interpretable Machine Learning 2020/2021 elective course. Find more details about the MIM classes here and about the faculty, here. The Department of Econometrics, University of Łódź TODO. Prof Paweł Baranowski is the lead collaborator from UoŁ. 0.5 About business partner McKinsey &amp; Company TODO "],["team-1.html", "Chapter 1 Team 1 1.1 Introduction 1.2 Model 1.3 Explanations 1.4 Summary and conclusions", " Chapter 1 Team 1 Authors: Group 1 Mentors: Group 1 1.1 Introduction 1.2 Model 1.3 Explanations 1.4 Summary and conclusions "],["team-2.html", "Chapter 2 Team 2", " Chapter 2 Team 2 Authors: Adrian Stępaniak (EkSoc UŁ), Piotr Grabysz (MIM UW), Piotr Kuczko (MIM UW) Mentors: Adam Zmaczyński (Consultant), Karol Skorulski (Data Scientist) "],["introduction-1.html", "Chapter 3 Introduction", " Chapter 3 Introduction Our team’s task was to find the most seasonal products among all sold products and predict their future sells. This projects required answering this three important questions: how to distinguish which product is more seasonal than the others? what kind of seasonality should we analyze, e.g. change of sells during the year or week or maybe even the fluctuations of product’s sales over the single day? are there any other useful data for prediction beside Shumee’s retail dataset? We answer question 1. and 2. in the section Most seasonal products and the question 3. in the section Model for predicting future sales. It is important to note here that in the very early stage of the project we run into some difficulties and addressing them required a lot of data preprocessing. We keep the section Data preprocessing at the end of this article to not distract the reader from the main findings. But we would like to emphasis that data preparation was an important and a time consuming part of our work. "],["the-most-seasonal-products.html", "Chapter 4 The most seasonal products", " Chapter 4 The most seasonal products 4.0.1 Data representation Before doing any further analysis, we grouped similar products as one cluster. It is described in greater details in the section Data preprocessing but here we give just some examples: group zestaw wypoczynkowy contains * Zestaw wypoczynkowy, 14 elementów, naturalny rattan * Zestaw wypoczynkowy, 27 elementów, naturalny rattan * 6-cz. zestaw wypoczynkowy do ogrodu, poduszki, rat * and many many more group stolik krzesła contains: * Stolik i krzesła barowe, 3 elementy, drewno’, * Stolik i krzesła barowe, 5 elementów, lite drewno akacjowe’, * Stolik i 2 krzesła z mozaiką niebiesko-białą’, * and many many more 4.0.2 Seasonality measure Now we would like to measure which of these groups exhibit the strongest seasonality in terms of number of sales. We use the seasonality measure which is described here [https://otexts.com/fpp2/seasonal-strength.html]. In this method the time series is decomposed into trend, seasonal component and remainder: \\[ y_t = T_t + S_t + R_t \\] The strength of the seasonality is described as: \\[ F_S = max(0, 1 - \\frac{Var(R_t)}{Var(S_T + R_t)} \\] A rationale behinds this is that for strongly seasonal data the detrended time series should have much more variation than the remainder component has alone. 4.0.3 What kind of seasonality? Now it is time to answer the question of what period of times do we want to analyse. At first we thought about tracking the sales changes through the week, especially changes between working days and weekends. But let’s plot the bar plot of mean number of sales for every weekday: We were quite surprised by the fact that sales drop every day from Monday to Saturday. We were told by Shumee’s representative that this is because some transaction have the delay between the payment and the confirmation from the bank. That is why some transactions actually made by customers on a weekend are not visible in Shumee’s data until Monday. So we decided to not analyse the weekly seasonality, becuase the model based on this delayed data could drift far away from real customers behaviour. We think that the best solution is to consider monthly seasonality. Taking longer periods of time evens out the noise of delayed payments. On the other hand monthly seasonality is not so coarse as quaterly seasonality and could potentially capture more subtle patterns. 4.0.4 The most seasonal products The groups of products that gained the greatest \\(F_S\\) measure are shown in the table: Name of products group seasonality strój świętego 0.881225 szlafrok unisex 0.757613 naciągany pokrowiec 0.740653 siatka ogrodzeniowa 0.721494 ostrzałka pił 0.718631 zestaw wypoczynkowy 0.718409 stolik krzesła 0.709425 ogrodowy stół 0.708391 donica gabionowa 0.701651 ławka wokół 0.700390 Let’s see the sales of strój świętego: Whereas it has perfect seasonal pattern it was sold only 11 times during the whole period of Shumee’s existence. It is too little to train any model, so we should disregard groups that aren’t sold up frequently enough. Actually, we left only 100 best-selling groups, starting from lampa (4022 sales), elastyczne pokrowce (2680 sales), dywan (2674 sales) and ending with ścianki boczne (204 sales). Among those 100 best-selling products the most seasonal are: Name of products group seasonality siatka ogrodzeniowa 0.721494 zestaw wypoczynkowy 0.718409 donica gabionowa 0.701651 zestaw mebli 0.679052 parasol ogrodowy 0.669685 kosz gabionowy 0.658801 markiza 0.612309 klatka dla 0.604560 zaczepy do przyczepki 0.592115 ławka ogrodowa 0.586771 Their respective plots are: Visualization of the seasonal component of 20 most seasonal products: It can be seen that almost all of this products were sold the most often between March and August. Now we choose some of this most seasonal products to train some models for future predictions. "],["model-for-predicting-future-sales.html", "Chapter 5 Model for predicting future sales", " Chapter 5 Model for predicting future sales For sales predicting we use Prophet, a tool developed by engineers from Facebook for time series forecasting. While it is a very powerful model there are no ready-to-go XAI techniques. We describe some of our proposals later. We wondered what additional information could be useful in forecasting. We came up with this ideas: Google trends - one can use Google trends to get the popularity of any given query made in google browser. We thought that this might be potentially useful. Our guess was that seeing increase in popularity of some products in Google one should expect increase in sales of these products. Temperature - mean temperature in Poland in a given month. Restricting our interest only to Poland’s temperatures is valid since we only use products sold in Poland anyway. The reason behind using it is that the most seasonal products have the peak in their sales in spring and summer, as we could see in the previous section. They are frequently associated with outdoor activities. So can rising temperatures anticipate the boom in tents or garden chairs sales? New cases of coronavirus - new cases of coronavirus in a given month in Poland. The pandemic undisputably affected a lot of different areas in our life. But it may be especially related to our shoping activites. Firstly, because large number of covid cases has been forcing stationary shops to be closed. It is clearly visible in Shumee data that their fast growth is even greater after March 2020. But secondly there is also a chance that the pandemic changed what people find valuable to buy and what they want to buy. Total number of all sells of all products in a given month. First of all it is worth taking a look at the correlation between the seasonal products and the proposed regressors. As an example we show correlation between sells of markiza and each individual reggresor: We can see that Shumee fastly grows. So we will predict sells of a given product devided by total number of sells in a given month. Because trend of Shumee sells depends on many things like: business decisions, market competition and others. This is very difficult to predict by any artificial intelligence model, so we simplify our problem. First problem which we met was: how to measure the model’s error? This problem appears because we build separate models for each product. We decided to split timeseries to train and test sets in a following way: train set contains data from 2018-02 to 2020-11 and test set contains 2020-12 to 2021-02. We train the FB Prophet model on the train dataset and we measure error on the test dataset using mean squared error metric. "],["model-explanation.html", "Chapter 6 Model Explanation", " Chapter 6 Model Explanation We see that we must build own tool for model explainability, because there are no existing ready-to-go XAI techniques for a prophet model. We decided to implement feature importance based on a column drop. It works in the following way: we select one column and we drop it. For the rest of attributes we add the columns to fbprophet as reggresors and we train model. After that we can compute the error on the test dataset for this model and we devide it by error of whole model, where in whole model we have all attributes added as reggresor. Then we can do this for all attributes. Using this method we get feature importance for single products. In the next step we want to calculate feature importance for many products. We decided to take geometric mean to average importance for many products. In the chart below we can see feature importance for the top 10 most seasonal products. If a value for the attribute is greater that 1.0 it means that adding this attribute decreases error of the model, otherwise adding attribute increases error. We can see easily that the most important attributes are temperature and google trend on the second place and they increase quality of the model. Attributes like Covid and the total number sells mostly decrease quality of the model. Now we can compare it with feature importance for top 10 least seasonal products. We can see what we would expected because temperature is not the most important factor for non seasonal products. We have google trends instead as the most informative regressor. Whole sells has very low feature importance and its value is strictly less than 1.0, meaning that it does worsen our model. This tool can be used to select attributes which are the most seasonal. We can calculate feature importance and if on first place is temperature or any other attribute, which is connected with seasonality, we can consider this attribute as a seasonal one. "],["data-preprocessing.html", "Chapter 7 Data preprocessing", " Chapter 7 Data preprocessing The first thing to note out is the dynamics of Shumee’s retail growth This rapid growth is very good news for Shumee but it means some problems for data analyst. Although we have data collected over three consecutive years, which sounds like a decent amount of data, there is in fact very little data from 2018 and 2019. This puts us in a risk of gathering noise rather than robust patterns of clients’ behavior. It is possible that there is too little sells to capture true seasonality in 2019 and especially 2018 year. What complicates things even more is that there is 41k unique products in the dataset and 160k transactions in total. This means that every product was sold only four time on average. That might be hard to find any seasonality at all! Let’s see if there are any products which were sold significantly often: We can see here that the products sold the most were actually sold only 400 times - during the three years period. So it is clear that we need to group similar products so that every such group contains enough data to perform analysis on it. But it is not that obvious how to do it because we can not rely on semantic similarity alone. Consider this example: chair and garden chair are semantically close, but in the view of our retail analysis they are completely different products: we would expect seasonality from garden chair but not from any chair. Another products which are semanticaly similar but actually completely different are garden fountain and chocolate fountain, because this products have same noun but different adjective. This rule does not work for green carpet and red carpet which are essentially the same products. So what we did to overcome those problems is an amalgamation of simplifying the names, measuring their similarity based on just the letters, NLP and some dirty work of manually grouping those products. First thing which was done was data clearing. We removed data from other domains (rynków) and we considered only data from polish domain(rynek). We removed transactions with names suggesting that they was added for testing purposes. They often contained words : “test,” “ssss.” In the next step we removed from products’s names things like: product brands, colors, materials from which they were made, size, other insignificant informations. To group the same products we used DBSCAN clustering. The metric used for clustering was based on the levenshtein distance. Using this transformations we achieved 9k groups which we used to analize retail and seasonality. "],["team-3.html", "Chapter 8 Team 3 8.1 Introduction 8.2 Model 8.3 Explanations 8.4 Summary and conclusions", " Chapter 8 Team 3 Authors: Group 3 Mentors: Group 3 8.1 Introduction 8.2 Model 8.3 Explanations 8.4 Summary and conclusions "],["story-sales-prediction.html", "Chapter 9 Story Sales Prediction 9.1 Introduction 9.2 Data 9.3 Long-term sales forecasting 9.4 Short-term sales forecasting 9.5 Summary and conclusions", " Chapter 9 Story Sales Prediction Long-term and short-term sales predictions based on historical data and product categories Authors: Mateusz Sieniawski, Michał Raszkowski, Piotr Krzywicki, Stanisław Antonowicz, Adam Sobiński Mentors: Błażej Wiórek, Miłosz Dobersztyn 9.1 Introduction The use of machine learning and deep learning in business settings is rapidly evolving in recent years. In particular, e-commerce companies implement AI-based solutions to aid them in following tasks: Recommendation systems Zhang et al. (2019) Business decision making, which might include: Lowering or increasing product prices Ferreira, Lee, and Simchi-Levi (2016) Predicting general consumer demands Van Nguyen et al. (2020) Fraud detection Nanduri et al. (2020) Sales prediction Cadavid, Lamouri, and Grabot (2018) In this project, we decided to explore the last problem: forecasting future profits based on historical sales data. We used the data provided by shumee (https://shumee.pl), a Polish e-commerce company mostly selling various household products online. Additionally, all of our models are interpretable using multiple explainable machine learning techniques such as SHAP Lundberg and Lee (2017), LIME Ribeiro, Singh, and Guestrin (2016), PDP Friedman (2001), Ceteris Paribus Profiles Goldstein et al. (2014), and Variable Importance Fisher, Rudin, and Dominici (2019). Most of these popular XAI methods are implemented in dalex package Biecek (2018). 9.2 Data 9.2.1 Overview The data consisted of a list of around 180 thousand orders starting in February 2018 and spanning three years. This dataset proved to be challenging because the three-year time period is too short to allow learning yearly trends. Moreover, essentially the only information that was available about products was their name. Another obstacle was that shumee is a small, yet rapidly growing company. An obvious rising trend can be observed in the graph of sales. Monthly shumee sales from February 2018 to February 2021. During the global COVID-19 pandemic (which started in Poland in March 2020), many e-commerce companies observed an increase in sales. As we can see from the graph above, this was also the case with shumee. Another crucial factor was that the company has been expanding and has entered new markets in European Union, two of the biggest being Czech and Slovak markets. Because of those factors, after some preliminary experiments we decided that we won’t use time series-specific methods like ARIMA or a more recent Prophet Taylor and Letham (2017), as they weren’t able to accurately predict even a couple of days or weeks of sales. Instead, we used traditional machine learning models suitable for learning non-linear relationships. Column Description Order ID Cart ID – products bought together had the same order ID Date Date of order (with minute-level resolution) Source Distributor of the product Country These three columns regard the client address City ZIP code Product name Product names were in multiple languages, mostly in Polish SKU Stock keeping unit (https://en.wikipedia.org/wiki/Stock_keeping_unit) EAN International Article Number (https://en.wikipedia.org/wiki/International_Article_Number) Quantity Product Price Currency Delivery cost Delivery type E.g. which courier company was delivering the product Log-Histogram of missing labels To clean the data we removed products with missing or negative prices. We also unified the language of product descriptions to Polish using third-party translation software deepL (https://www.deepl.com/). Finally, the currencies of all orders were unified to euro according to the currency exchange rate in a day of a given order. In the original data, there was no information about product categories. Initially, we wanted to retrieve it from SKU and EAN, but unfortunately, these didn’t carry any meaningful insights about the product. A large number of rows are missing these, and each distributor has its own naming conventions. We wanted to take advantage of categories assigned to each product, therefore we scrapped around 30 thousand product categories from the shumee official website. The product categories turned out to be organized at three levels. Hierarchy of product categories The last one was too fine-grained and sometimes contained product names, so we decided to only use the first two. For example, a first-level category Dom i wnętrze had two sub-categories: Meble and Oświetlenie. The distribution of the amount of first-level product categories looks as follows: Log-histogram for product categories 9.2.2 Assigning missing categories About 2/3 of products didn’t have categories assigned. We solved this issue with the nearest neighbors approach. We used spaCy Honnibal et al. (2020) library for obtaining part of speech tags and also word vectors for each word of product description. We then averaged word vectors of nouns and adjectives. The UMAP McInnes, Healy, and Melville (2018) plot constructed on word vectors shows that products in each category are very diverse. But they generally form small subclusters in which the nearest neighbor query might work correctly. UMap visualization of product categories The resulting vectors for each known product were put in a KDTree data structure for fast nearest neighbor queries. The model achieved 90% accuracy and 81% balanced accuracy on a 10-fold cross-validation. We also prepared LIME instance-level explanations of our model. kNN for category classification – LIME explanations 9.3 Long-term sales forecasting The long-term sales figures forecasting might have a crucial impact on the company’s strategy. We prepared a machine learning model, which can forecast up to a few months of future sales. 9.3.1 Model description On the left: Prediction of our model vs actual data – grey line divides train/test sets. On the right: Three-month forecast by our model We used a random forest model that predicted the daily value of sales i.e. given a day, what will be the total value of all products sold this day. The training was done on the whole dataset, except for the last two months that were used later for testing. To tune hyperparameters, we utilized the optuna Akiba et al. (2019) framework, which automatically searched for the best parameters with regard to MSE score on cross-validation. For cross-validation we used TimeSeriesSplit from sklearn Pedregosa et al. (2011) to assure time contiguity and that the model can not use data coming from the future. The model uses as input: The number of products sold in each first-level category averaged over three two-week windows in the past Information whether we are after or before the start of the COVID-19 pandemic Date (year, month, day, weekday) The model uses as input the number of products sold in each first-level category averaged over three two-week windows in the past MAE RMSE MAE avg. over months RMSE avg. over months Value in euro 3335 4230 1211 1288 Table of metrics on the test set. The model predicts sales figures with daily resolution. Its predictions could be summed over whole months. The two rightmost columns show an averaged error in such a case, which is relatively small – MAE averaged over months is 8,7% of mean sales value and RMSE averaged over months is 9,3% of mean sales value. 9.3.2 Model explanations 9.3.2.1 Global explanations global SHAP explanations of the long-term model It represents the 20 variables that had the greatest impact on the predictions of the model. At the top of the chart, there are variables with the largest SHAP attributions. For example, Ilosc_Budowa i remont_120_w14 was the most important variable. Let’s break down the name of this feature: Ilosc means the number of products sold in the category Budowa i remont 120 days ago averaged throughout the length of 14 days. An important observation is that the three most important product categories to the model (Budowa i remont, Dom i wnętrze, Ogród) are also the top three first-level categories in terms of the number of orders. This suggests that the model properly recognizes the importance of each category. We also prepared Partial Dependence Plot explanations to get insight into how a change of one feature impacts the overall predictions of the model: Partial dependence plots for long-term model wrt different features The trend is clear – as the number of products sold in a given category rises, so does the predicted value of sales. This makes sense, as more products sold in the near past influence the value of products sold today. However, after some critical value, the graph flattens out. This suggests that the model is prone to overfitting i.e. a big change of products sold in only one sub-category does not influence the total sales value drastically. 9.3.2.2 Instance-level explanations We prepared instance-level SHAP explanations, which give insight into which features had a deciding effect on the final prediction. The graph below presents an example explanation of predicted sales for 17th January 2021. By looking at the graph, one can see that variables colored red are increasing the value of prediction, while those colored blue decrease it. In this particular example, the predicted total value of sales is much higher (26,6k €) than the base value (13,8k € – the averaged sales value in the training dataset). The factors that influenced the model prediction the most are similar to those in the global SHAP explanations. SHAP local explanation of prediction for 17th January 2021 17th January 2021 was almost a year after the start of the COVID-19 pandemic. The red bar stands for the real value of sales, while the blue one is the hypothetical value of sales if there was no pandemic. With this plot, the final user can answer the question: “What would the total sales figures look like if the pandemic didn’t happen?” 17th January 2021 if the pandemic didn’t happen Another type of instance-level explanation we prepared was Ceteris Paribus profiles, which can provide information on how in the case of a particular observation, the total sales value would change if the value of a given feature would change. These profiles regard the same observation as instance-level SHAP explanations presented above. In the following graphs the red dot symbolizes the real value of sales, while the blue line shows the model prediction if a given feature value changed. Ceteris paribus profile for 17th January changing the weekday We observed an interesting trend regarding the weekdays. The largest sales figures are on Mondays and are slowly decreasing throughout the week, until the lowest point, which happens on Saturdays. The model successfully captured this trend as visible in the graph above. Later on, the shumee representatives confirmed that this trend is in fact happening and our model properly understood it. Ceteris paribus profile for 17th Januray changing the volume of Garden and House categories The Ceteris Paribus profiles for categories look very similar to the PDP plots. The highly dynamic, almost discontinuous graphs are due to the fact that we used the random forest as our primary model. For example, in the case of neural networks, these graphs would look smoother. Anomaly in ceteris paribus sales dynamic We also observed an anomaly. In most PDP and Ceteris Paribus plots, a higher number of sold products in a category results in greater overall sales figures. However, in this profile, it is quite the opposite. This phenomenon is intriguing, yet the explanation is quite simple. If the sales figures in the recent few months were ‘flat’ then if the number of sold products 5 months ago were lower, it would suggest the existence of a rising trend, increasing the total sales prediction. Explanation of the anomaly in sales dynamic 9.3.2.3 Choice of model features In this section, we explain why we have chosen the aforementioned input variables. Most of the comparisons were based on train and test metrics – mainly MAE &amp; RMSE. But the interesting ones utilize XAI techniques, which allow us to understand how our model works and adjust the input variables accordingly. 9.3.2.3.1 Two-week windows We wanted to know how large the rolling window over which we average sales numbers should be. Therefore, we built a model which used windows of multiple sizes: 1, 7, and 14 days. The SHAP attributions for this model looked as follows: SHAP attributions with window sizes of 1, 7, 14 We can see that this model looked almost only at the two-week windows. Also, the two-week windows were always more important than the other window sizes. Additionally, this model has around 10% worse performance on the test set compared to our final model. It may suggest that additional window sizes in the model inputs make it overfit more. 9.3.2.3.2 Using the number of sales only Model predictions using counts only vs Model predictions using counts and values Initially, our model was trained on both the number of products sold, as well as the total value of products sold per category. At one point, we decided to check how the performance would change if we were to train it on the number of products sold only. To our surprise, the latter performed around 50% better on the test set while maintaining similar errors on the train set. We believe that adding this additional information rendered the model prone to overfitting. 9.3.2.3.3 Before/after start of pandemic Considering the impact of the COVID-19 pandemic on the global economy, we decided to include information about it for our model. At first, our model used the number of days before or after the start of the pandemic. However, the addition of this variable caused huge problems with overfitting, which can be seen on the global SHAP attribution graph below. Shap attributions with new Days_since_covid feature included Replacing this feature with a boolean flag for whether we are before or after the pandemic helped tremendously. The model performance on the test set improved by roughly 45%. 9.4 Short-term sales forecasting In the previous section, we analyzed a regression problem: “What will be the total sales figures value three months from now?” In this section, we looked at this problem from a different perspective, as a classification problem. The question we try to answer here asks: “Is sales figures’ total value going to be higher or lower than in the previous day?” 9.4.1 Models’ description The use-case of this short-term model is significantly different from the long-term one. Now we want to predict highly dynamic changes that happen over a time span of several days. This makes it possible to, for example, quickly create appropriate coupon strategies which suit customers’ preferences at a given time. Ours long term regression vs short-term classification approaches Moreover, it’s viable to look at the most recent data points when making sales predictions for the next day. If we were to use our previous long-term model for such a task, we wouldn’t take into account the sales value from the last few immediate days, despite the fact that they provide much of the precious information. To this end, we developed short-term models in which inputs are sales (volume and total price) divided into particular subcategories over the span of 5 last days. We also provide weekday, month, and year to the model inputs. For models different than decision-tree-based, we decided to use the one-hot encoding of months and weekdays. Otherwise, models such as linear regression would have been at a significant disadvantage. To solve this short-term classification problem we trained three models: adaboost gradient boosting method using sklearn lasso logistic regression fully connected feed forward neural network For AdaBoost and logistic regression default parameters from sklearn worked fine, and further hyper-parameter search gave very similar results, so we stayed with default ones. Only the neural network approach required manual extensive tuning. To make this approach work, we find out the architecture, which consists of two hidden layers of size 32, ReLU activations, dropout of 0.5, batch-normalization, optimized using the Adam optimizer. Despite all these regularization techniques, the neural network approach overfitted the most getting results subpar to AdaBoost and logistic regression. 9.4.2 Results Balanced accuracies of different models for short-term movement classification All classification models predicting whether the sales will move up or down significantly outperformed simple baselines such as returning last movement class. The AdaBoost model got the best balanced accuracy score of all models, suggesting the need to leverage input variables’ interaction. The logistic regression model, which scored as the second, won’t capture such interaction. The third and last was the neural network model. Generally, those models perform better on unstructured data while not as great on tabular data as the previous two. ROC curves of different models for short-term movement classification We also illustrated the models’ performance using ROC (receiver operating characteristic) curves, which show false positive and true positive rates of the model for a given threshold. Again, this time comparing the AUC score (Area Under Curve), the AdaBoost model works best, followed by logistic regression, then by the neural network. One can observe that it is possible to choose a threshold value such that the gradient boosting model has a true positive rate of 0.5 while maintaining a false positive rate of 0. In other words, when the model says the sales value will go up, with a very high probability it will go up. That property can certainly be used for shumee’s competitive advantage. 9.4.3 Models’ explanations Permutational variable importance of trained models We calculate the global permutational variable importance of input features for each model. Overall, the most important feature was the weekday. In the case of AdaBoost, it had an enormous impact on model prediction. For the other two models, it was divided into effectively six different variables via one-hot encoding. From these variables, the ones indicating Saturday, Sunday, or Monday carried greater importance. This matches with an observation that the significant change in sales dynamic happens for these weekdays. Aggregated partial dependence profiles illustrating sales dynamic wrt weekday Given that weekday is the most important variable, we investigate its dynamic using partial dependence profiles. We come to the conclusion that the same trend as in the long-term predictions can be observed here in the PDP of the weekday feature. The probability that the sales value will rise decreases throughout the week, having the lowest value on Saturday and the highest value on Monday. 9.4.4 Why don’t we use short-term regression model instead We used a classification model because short-term regression models’ quality was mediocre and comparable to simple baselines such as returning last sales value or exponential moving average. In other words, for this particular dataset, short-term sales regression is a harder problem than short-term sales movement classification, in which we got surprisingly good results (80% balanced accuracy). We came to this conclusion by comparing gradient boosting short-term regression model (with the same inputs as described above) to 3 simple baselines: Standard xgboost algorithm, with taking inputs from different number of days into account Constant model, which returns mean value over test set (first two months of 2021) Model which returns sales value from the previous day Exponential moving average of sales values with different effective window sizes Comparison of short-term regression models to simple baselines The interesting fact of this comparison is the dynamic of exponential moving average wrt effective window size. Compared to xgboost model, which has seemingly non-structured dynamic wrt window-size, exponential moving average has very regular error dynamic, which decreases with window size up to 8-10 and then increases. 9.5 Summary and conclusions We prepared sales forecasting machine learning models based on data provided by shumee, a Polish e-commerce company. Our main focus was on long-term (up to a few months) sales figures forecast, but we also tackled the problem with a shorter prediction time span. These models can have a major impact on the strategy of the company with serious business applications. Our main long-term predictions could help more precisely foresee the growth of shumee, as well as anticipate demand in the broader time horizon. The short-term model can give insights into the dynamic, day-to-day sales changes. This makes it possible to, for example, create appropriate coupon strategies which suit customers’ preferences in no time. We utilized multiple XAI techniques, which gave us insight into which variables are the most important and how they influence the predictions. Using them, we successfully debugged and improved the quality of our models. Moreover, the final user does not have to treat the models as black-boxes thanks to instance-level explanations. One can get meaningful information about how they work underneath and explain their predictions. References "],["temperature-vs-sales-prediction.html", "Chapter 10 Temperature vs sales prediction 10.1 Introduction 10.2 Model 10.3 Explanations 10.4 Summary and conclusions", " Chapter 10 Temperature vs sales prediction Authors: Olaf Placha (University of Warsaw), Tomasz Kanas (University of Warsaw), Maciej Twardowski (University of Warsaw), Wiktoria Zapart (University of Łódź) Mentors: Alicja Jośko (McKinsey), Maciej Andrzejak (McKinsey) 10.1 Introduction A constantly asked question is “How to improve sales?” There are many factors which have an impact on sales. One of them could be weather, which is why in this part we are going to analyse if weather have an actual impact on sales. Thanks to cooperation with Shumme S.A, orders on products of the company were provided as the dataset for this project. In particular, information such as date of the order (all orders were made between 2018 and 2021), country, zip code, product name, volume and price were further used to category selection and model construction. Additionally, dataset was extended by weather information and category of the products. Weather information such as daily average temperature and total daily precipitation were retrieved from the institute of meteorology and water management database. Using first digits of zip code information we divided our data into 10 regions which we matched with accumulated weather data we obtained. In the process of category selection we choose two categories which will be further analyzed and used in model. First group covers products which we can classify as garden product (mostly furniture and accessories), second group covers products which we can classify as home category (also furniture and accessories). We also filtered only these orders which were placed in Poland. Below is an overview of total sales (without splitting into categories), average temperature and precipitation. FIGURE 10.1: Daily total sales, average temperature, precipitation in millimeters An overview of garden products sales and temperature: FIGURE 10.2: Daily garden products sales vs average temperature Beside the description of the data and specification of the problem of this paper, following subjects will be covered: model construction categories selection model exploration instance-level exploration summary. 10.2 Model 10.2.1 Product Categories One of the first problems we faced was the categorization of products. We did not want to model sales of each product separately, but instead wanted to focus on a smaller number of distinctively different categories. Below was explained the process that led to choosing 2 product categories of which sales were finally modelled: Garden and Home. Our initial approach was to automatically categorize products using polish word2vec embeddings and run K-Means clustering algorithm on vectorized product names. This proved to be problematic: Setting a small number of clusters (between 5 and 15) resulted in seemingly unrelated products clumped in the same clusters. On the other hand, setting a larger number of clusters resulted in too small number of products in each of them. Time series of total sales of such small ‘categories’ had low values and seemed to contain a lot of noise. Also, inspecting the quality of clusters required a lot of manual work. This leads to a simpler approach that was actually used: simple categorization of products based on their names containing manually selected keywords. There were 5 predetermined categories: Garden, Home, Clothes, Toy, Industry. If a product name contained a keyword (for example “taras” i.e. terrace in Polish) specific to one of these categories, it was enough to assign category label to it (in this case Garden). In total, there were 187 keywords used, which allowed to categorize 25.000 out of 40.000 product names, responsible for more than 70% of global sales. Moreover, Garden and Home turned out to be responsible for more than 50% of global sales. Since in this project we were interested in the relationship between weather and product sales, they seemed like a great fit. Sales of Garden category products had a distinctive yearly seasonal pattern, unlike Home products. FIGURE 10.3: Total sales of Garden and Home products 10.2.2 Training and testing procedure Each model was trained and tested on 12 different train and test datasets. Each training dataset contained data ranging from January 1 2019 to THRESHOLD_DATE. It was then tested on each of 21 next days from THRESHOLD_DATE. These “threshold” dates are marked above on Figure 5.1. They uniformly covered the year 2020. This way of splitting train and test datasets ought to mimic a real-world scenario in which predictive models are retrained periodically and gives a more representative view into models’ performance over the whole year than a single division of data into train, test (and possibly validation) sets. There were some records from the end of 2018 year, but they were discarded due to very small and unstable sales volume values. As a validation metric we had chosen Median Absolute Error and later on looked at error distributions for 12 train/test datasets and particular models. Median version of this metric was chosen over the “Mean” one due to occasional anomalous sales values occurring in the data which could distort the results. One of the main benefits of the used metric is its simplicity and interpretability. It’s drawback is that it needs some reference to assess whether obtained values are “good” or “bad”; this reference was provided by evaluating a benchmark model that always predicts no change in daily sales volume. 10.2.3 Evaluated models 10.2.3.1 Benchmark To obtain some reference to models’ quality metrics, a simple benchmark model was used. This model “predicts” the same daily sales volume as was observed in the current day. 10.2.3.2 Arima &amp; FB prophet models Further, pure time series models were considered, meaning the ones that only used the information of historical daily sales volumes for each of selected categories. These were ARIMA (autoregressive integrated moving average) model and a Generalized Linear Models from FB Prohpet library which incorporates trend, seasonal components and prediction uncertainty. 10.2.3.3 Random Forest Finally, we incorporated a model that actually used weather information while predicting the next day’s daily sales volume. This was a Random Forest model that turned out to be the most effective. It used features such as: product category (garden / home) daily sales volume - today and mean over previous six days temperature - today and mean over previous six days precipitation - today and mean over previous six days day of week month region (unused in the final model) Two versions of Random Forest models were evaluated. The first one predicted absolute volume of next day sales and the second one predicted the difference of daily sales volume with respect to the current day. Differencing daily sales volume (as in the second version of the model) removed the trend from the time series; this can be seen below on Figure 5.2 FIGURE 10.4: Differencing daily sales volumes detrends the time series. 10.2.3.4 Models’ effectiveness The Random Forest models incorporating among others weather information were found to be the most effective. Their Absolute Median Errors were frequently 30-40% lower compared to the benchmark model. Simpler models that used only historical sales volume data were not as good, but still significantly better than the benchmark. The average Median Absolute Errors (in PLNs) for each model and category are presented below: Detrended Random Forest: ~4300 (Garden), ~4800 (Home) Random Forest: ~4500 (Garden), ~5000 (Home) Arima &amp; FB prophet: ~5200 (Garden), ~6500 (Home) Benchmark: ~6000 (Garden), ~8000 (Home) FIGURE 10.5: Distribution of Median Absolute Errors for Garden (up) and Home (down) sales prediction 10.3 Explanations Explaining models’ decisions can give valuable insights into what determines the predicted value. Our explanations focused on weather importance. We divided the explanations into instance-level explanations and model-level explanations. 10.3.1 Instance-level explanations FIGURE 10.6: SHAP values from one prediction - garden accessories Above you can see SHAP values of one of the predictions. It is not surprising that the most influential feature was the mean sales from the previous 6 days. In this case it was substantially above the average. Moreover, moderate total sales from the previous day had a negative impact on the next day’s sales. What is also not very surprising is the fact that the day of the week, which is in this case Tuesday, also reduces expected sales. It aligns with Shumee representatives’ observations, as they usually expect enhanced sales during weekends. Most importantly, the precipitation and the temperature had a negligible impact on the prediction. But maybe it is because the values were around the average? We definitely need more explanations to answer this question. FIGURE 10.7: SHAP values from one prediction - home accessories Now you can see another prediction. Contribution of the features to the prediction is similar. Likewise, the weather didn’t impact the predictions substantially. But still, we can not be sure if weather has no impact on most predictions. There were just two examples. Let’s see how the predictions would change if we tweaked the weather values. To accomplish that we will use Ceteris Paribus Profiles. FIGURE 10.8: Ceteris Paribus Profiles of a few features On average, temperature and precipitation prediction is stable as we change the weather values. It lets us be more confident that the weather is not very important in the model’s predictions. 10.3.2 Model-level explanations To have even more holistic understanding of the weather importance we decided to do model-level explanations. Firstly, we calculated features’ permutational importance. It relied on fixing all features except for one and permuting the not fixed feature’s values. Average absolute percentage difference between the original prediction and the prediction after permutation indicated how important a specific feature is in the predictions. FIGURE 10.9: Permutational importance of features in case of home accessories Above you can see the permutational features importance in case of home accessories. The results are quite consistent with what we have obtained previously - average sales from the last 6 days as well as the day of the week are the most influential. Finally, we decided to build 3 models with different datasets. They were: - the original dataset - the original dataset without weather features - the original dataset without weather features, with the month number It turned out that all models performed better than the benchmark, but there were slight performance differences between the models. Namely, the model trained without the weather data, but with the month number, achieved the best score in both home and garden categories. It lets us assume that the weather is just a proxy for the season of the year. FIGURE 10.10: Models error when trained with different datasets 10.4 Summary and conclusions Ability to predict future sales is vital to any retail business. One can use black box machine learning model to compute such predictions, but knowledge what factors contribute to future sales may be even more insightful. Our task was to assess the impact of temperature on sales prediction. To achieve it, we firstly trained several machine learning models predicting future sales. Then we used few XML techniques to examine effect of weather on our predictions. Our experiments show little impact of weather on sales predictions. Both variable importance, and local explanation techniques showed some, although small, impact of weather, but model that used month number, instead of temperature and precipitation, achieved similar (even slightly better) results. It suggests, that the impact of weather in our models is mostly caused by a correlation between temperature and month. There are few possible reasons of such outcome. Firstly, we observe substantial impact of seasonality on sales. Temperature may have impact on this seasonality pattern. For example in one year summer increase in sales may come earlier than in other year, due to higher temperatures. Unfortunately, we had only 2 years of data, which is too short to be able to observe such pattern. Another possibility is that our model is not good enough to capture the impact of weather. There are many factors that affect sales, like seasonality, day of week or growth of the company. There was also outbreak of COVID-19 pandemic in the middle of examined period, which could affect shopping habits and made it harder to train good model. "],["acknowledgements.html", "Acknowledgements", " Acknowledgements This project is inspired by a fantastic book Limitations of Interpretable Machine Learning Methods created at the Department of Statistics, LMU Munich. We used the LIML project as cornerstone for this reopsitory. This book would not have been written without openness to cooperation of two universities: University of Warsaw and University of Łódź. Students from these universities collaborated (remotely due to the Covid-19 epidemic) on their chapters. My biggest thanks go to two people from McKinsey, who have been supporting my classes on UoW and WUT for years, inspiring it with ideas for new challenges, ideas and solutions. Mateusz Zawisza and Amadeusz Andrzejewski, thank you very much! Przemysław Biecek, June 2021, Warsaw "],["references.html", "References", " References "]]
